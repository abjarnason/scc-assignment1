Question 2. a)

Please add your run log along with commands to below in this file.
===================================================================

//compile CombineBooks.java and create a jar (java-json.jar has to be added to the lib/ directory of hadoop-1.2.1)

$ mkdir combinebooks_classes
$ javac -classpath /home/hadoop/hadoop-1.2.1/hadoop-core-1.2.1.jar:/home/hadoop/hadoop-1.2.1/lib/commons-cli-1.2.jar:/home/hadoop/hadoop-1.2.1/lib/java-json.jar
$ jar -cvf combinebooks.jar -C combinebooks_classes/ .

added manifest
adding: org/(in = 0) (out= 0)(stored 0%)
adding: org/hwone/(in = 0) (out= 0)(stored 0%)
adding: org/hwone/CombineBooks$Map.class(in = 1899) (out= 821)(deflated 56%)
adding: org/hwone/CombineBooks$Reduce.class(in = 2171) (out= 963)(deflated 55%)
adding: org/hwone/CombineBooks.class(in = 1877) (out= 962)(deflated 48%)

// create input/ folder and move .txt file into it..

$ hadoop fs -mkdir input
$ hadoop fs -copyFromLocal author_book_tuple.txt input

// run the program with input file from input/ and save output in output/

$ hadoop jar combinebooks.jar org.hwone.CombineBooks input output 

Warning: $HADOOP_HOME is deprecated.

14/11/10 10:35:21 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
14/11/10 10:35:22 INFO input.FileInputFormat: Total input paths to process : 1
14/11/10 10:35:22 INFO util.NativeCodeLoader: Loaded the native-hadoop library
14/11/10 10:35:22 WARN snappy.LoadSnappy: Snappy native library not loaded
14/11/10 10:35:22 INFO mapred.JobClient: Running job: job_201411101027_0003
14/11/10 10:35:24 INFO mapred.JobClient:  map 0% reduce 0%
14/11/10 10:35:47 INFO mapred.JobClient:  map 7% reduce 0%
14/11/10 10:35:50 INFO mapred.JobClient:  map 100% reduce 0%
14/11/10 10:36:09 INFO mapred.JobClient:  map 100% reduce 66%
14/11/10 10:36:13 INFO mapred.JobClient:  map 100% reduce 71%
14/11/10 10:36:16 INFO mapred.JobClient:  map 100% reduce 97%
14/11/10 10:36:17 INFO mapred.JobClient:  map 100% reduce 100%
14/11/10 10:36:25 INFO mapred.JobClient: Job complete: job_201411101027_0003
14/11/10 10:36:25 INFO mapred.JobClient: Counters: 29
14/11/10 10:36:25 INFO mapred.JobClient:   Job Counters 
14/11/10 10:36:25 INFO mapred.JobClient:     Launched reduce tasks=1
14/11/10 10:36:25 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=34686
14/11/10 10:36:25 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
14/11/10 10:36:25 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
14/11/10 10:36:25 INFO mapred.JobClient:     Launched map tasks=1
14/11/10 10:36:25 INFO mapred.JobClient:     Data-local map tasks=1
14/11/10 10:36:25 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=25339
14/11/10 10:36:25 INFO mapred.JobClient:   File Output Format Counters 
14/11/10 10:36:25 INFO mapred.JobClient:     Bytes Written=12217781
14/11/10 10:36:25 INFO mapred.JobClient:   FileSystemCounters
14/11/10 10:36:25 INFO mapred.JobClient:     FILE_BYTES_READ=9193604
14/11/10 10:36:25 INFO mapred.JobClient:     HDFS_BYTES_READ=12121912
14/11/10 10:36:25 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=18499559
14/11/10 10:36:25 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=12217781
14/11/10 10:36:25 INFO mapred.JobClient:   File Input Format Counters 
14/11/10 10:36:25 INFO mapred.JobClient:     Bytes Read=12121786
14/11/10 10:36:25 INFO mapred.JobClient:   Map-Reduce Framework
14/11/10 10:36:25 INFO mapred.JobClient:     Map output materialized bytes=9193604
14/11/10 10:36:25 INFO mapred.JobClient:     Map input records=146616
14/11/10 10:36:25 INFO mapred.JobClient:     Reduce shuffle bytes=9193604
14/11/10 10:36:25 INFO mapred.JobClient:     Spilled Records=293232
14/11/10 10:36:25 INFO mapred.JobClient:     Map output bytes=8896580
14/11/10 10:36:25 INFO mapred.JobClient:     Total committed heap usage (bytes)=185360384
14/11/10 10:36:25 INFO mapred.JobClient:     CPU time spent (ms)=21870
14/11/10 10:36:25 INFO mapred.JobClient:     Combine input records=0
14/11/10 10:36:25 INFO mapred.JobClient:     SPLIT_RAW_BYTES=126
14/11/10 10:36:25 INFO mapred.JobClient:     Reduce input records=146616
14/11/10 10:36:25 INFO mapred.JobClient:     Reduce input groups=109698
14/11/10 10:36:25 INFO mapred.JobClient:     Combine output records=0
14/11/10 10:36:25 INFO mapred.JobClient:     Physical memory (bytes) snapshot=307929088
14/11/10 10:36:25 INFO mapred.JobClient:     Reduce output records=109698
14/11/10 10:36:25 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=1501450240
14/11/10 10:36:25 INFO mapred.JobClient:     Map output records=146616

// finally we check the output

$ hadoop fs -copyToLocal output output
$ head -20 output/part-r-00000

{"author":" Antonio Zirardini","books":[{"book":"Degli antichi edifizi profani di Ravenna libri due"}]}
{"author":" E. M. Korkhmazyan","books":[{"book":"Armenian miniatures of the 13th and 14th centuries from the Matenadaran collection, Yerevan"}]}
{"author":" Edward J and G. Burrow","books":[{"book":"Little Lever Official Guide; published by Authority of the Little Lever Urban District Council"}]}
{"author":" I Uli i a Pavlovna Averkieva","books":[{"book":"Kwakiutl stringfigures"}]}
{"author":" Joseph L Ganey","books":[{"book":"Using terrestrial ecosystem survey data to identify potential habitat for the Mexican spotted owl on national forest system lands"}]}
{"author":" Keith Hemsley","books":[{"book":"The NCET primary data-logging project"}]}
{"author":" Leon Edel","books":[{"book":"Henry James The Treacherous years"}]}
{"author":" Paulo Ferreira","books":[{"book":"O Mensageiro \u2013 Vol. 1 \u2013 O Despertar para um Novo Mundo."}]}
{"author":"\"BB\"","books":[{"book":"Tides Ending"}]}
{"author":"\"BB,\"","books":[{"book":"Tide's ending"},{"book":"A summer on the Nene"},{"book":"Brendon chase"},{"book":"Ramblings of a sportsman-naturalist"}]}
{"author":"\"Creating a Universal Environment\" Conference (1991 Waterloo, Ont.)","books":[{"book":"Proceedings of \"Creating a Universal Environment\" Conference"}]}
{"author":"\"Edinburgh Evening News\"","books":[{"book":"Images of Edinburgh (Images of)"}]}
{"author":"\"Financial Times\"","books":[{"book":"World Desk Reference (World Atlas)"}]}
{"author":"\"Good Housekeeping\".","books":[{"book":"Using an ice cream maker"}]}
{"author":"\"Hebukesaier Menggu Zizhixian gai kuang\" bian xie zu","books":[{"book":"Hebukesaier Menggu Zizhixian gai kuang ="}]}
{"author":"\"Huan qiu qi ye jia \" za zhi she","books":[{"book":"Huan qiu qi ye jia"}]}
{"author":"\"J. J.\" \"Jones\"","books":[{"book":"Deirdre"}]}
{"author":"\"Organic Gardening and Farming\"","books":[{"book":"Calendar of Organic Gardening"}]}
{"author":"\"Penelope\".","books":[{"book":"Jacobean Crewel work and traditional designs"}]}
{"author":"\"Ren wu\" bian ji bu","books":[{"book":"Zuo ye chang feng yi zhi qin ="}]}

// in this output we can actually only see one example of more than one book by an author ("\"BB,\""). And then put it into the output-a/ directory

$ cp output/part-r-00000 output-a



